


import numpy as np
import pandas as pd
from matplotlib.pyplot import subplots
import statsmodels.api as sm
from statsmodels.stats.outliers_influence \
    import variance_inflation_factor as VIF
from statsmodels.stats.anova import anova_lm
from ISLP import load_data
from ISLP.models import (ModelSpec as MS, summarize, poly)








# Load Boston data set 
boston = load_data("Boston")
boston.columns


# lstat - percent of households with low socioeconomic status
X = pd.DataFrame({'intercept': np.ones(boston.shape[0]),
                 'lstat': boston['lstat']})
X.head()


# Extract response and fit model 
y = boston['medv']
model = sm.OLS(y, X)
results = model.fit()





summarize(results)





# Create a transform object
design = MS(['lstat'])
X = design.fit_transform(boston)
X.head()


results.summary()


# Predict medv on new lstat values
new_lstats = pd.DataFrame({'lstat': [5, 10, 15]})
newX = design.transform(new_lstats)
preds = results.get_prediction(newX)


# Predicted values
preds.predicted_mean


# Confidence intervals 
preds.conf_int(alpha=0.05)


# Prediction intervals
preds.conf_int(obs=True, alpha=0.05)


# Add line with slope m and intercept b
def abline(ax, b, m, *args, **kwargs):
    xlim = ax.get_xlim()
    ylim = [m * xlim[0] + b, m * xlim[1] + b]
    ax.plot(xlim, ylim, *args, **kwargs)


# Add regression line to medv vs. lstat
ax = boston.plot.scatter('lstat', 'medv')
abline(ax,
      results.params.iloc[0],
      results.params.iloc[1],
      'r-',
      linewidth=3)





# Residual plot
ax = subplots(figsize=(8,8))[1]
ax.scatter(results.fittedvalues, results.resid)
ax.set_xlabel('Fitted vlaue')
ax.set_ylabel('Residual')
ax.axhline(0, c='k', ls='--');


# Leverage plot
infl = results.get_influence()
ax = subplots(figsize=(8,8))[1]
ax.scatter(np.arange(X.shape[0]), infl.hat_matrix_diag)
ax.set_xlabel('Index')
ax.set_ylabel('Leverage')
np.argmax(infl.hat_matrix_diag)





# Regression with lstat and age
X = MS(['lstat', 'age']).fit_transform(boston)
model1 = sm.OLS(y, X)
results1 = model1.fit()
summarize(results1)


# Regression with all predictors
terms = boston.columns.drop('medv')
X = MS(terms).fit_transform(boston)
model2 = sm.OLS(y, X)
results2 = model2.fit()
summarize(results2)


# Drop age (high p-value)
sans_age = boston.columns.drop(['medv', 'age'])
Xsa = MS(sans_age).fit_transform(boston)
model3 = sm.OLS(y, Xsa)
summarize(model3.fit())





# R-squared
results2.rsquared


# RSE
np.sqrt(results2.scale)


# Compute VIFs for each variable
vals = [VIF(X, i) for i in range(1, X.shape[1])]
vif = pd.DataFrame({'vif': vals}, index=X.columns[1:])
vif





X = MS(['lstat', 'age', ('lstat', 'age')]).fit_transform(boston)
model4 = sm.OLS(y, X)
summarize(model4.fit())








X = MS([poly('lstat', degree=2), 'age']).fit_transform(boston)
model5 = sm.OLS(y, X)
results5 = model5.fit()
summarize(results5)


# Compare quadratic and linear fit
anova_lm(results1, results5)





# Residual plot of quadratic model
ax = subplots(figsize=(8,8))[1]
ax.scatter(results5.fittedvalues, results5.resid)
ax.set_xlabel('Fitted Value')
ax.set_ylabel('Residual')
ax.axhline(0, c='k', ls='--')











carseats = load_data('Carseats')
carseats.columns


allvars = list(carseats.columns.drop('Sales'))
y = carseats['Sales']
final = allvars + [('Income', 'Advertising'), ('Price', 'Age')]
X = MS(final).fit_transform(carseats)
model = sm.OLS(y, X)
summarize(model.fit())



